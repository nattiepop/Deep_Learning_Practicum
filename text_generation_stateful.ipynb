{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "inLc5F-9qOKA"
      },
      "source": [
        "# Generating Shakespearean Text \n",
        "In this exercise, you will train a character-level sequence model on a subset of Shakespeare's works (a single text file), and use it to generate novel text, one charactor at a time according to a distribution learned from the dataset. For this to be effective, we will build our  language model to be stateful, so that the internal state of the RNN will be maintained across batches. \n",
        "The Shakespearen Text used in this exercise has 65 classes (total distinct characters) with 1,115,394 characters.\n",
        "\n",
        "Besides tf.keras that you used previously, you will use the tf.data module preprocessing tools to construct a data ingestion pipeline including batching, shuffing the dataset to train a model to classify the next character. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EnajdppRbtb5"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf # version 2.9.2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Input, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
        "from tensorflow.keras.layers import TextVectorization, Dense, Flatten, Softmax, Dropout, Embedding, SimpleRNN, LSTM, GRU, Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYGK1SeHtuCh"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJNcT9VsgYJz",
        "outputId": "c91e981b-71e2-4d2f-bd5b-8534eb86d143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# download Shakespeare's work from Andreh Karpathy's Char-Rnn Project\n",
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQb06ktUtwJo"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oI0kbvlgfhy",
        "outputId": "bd74bf68-3f00-4971-df21-754fb61ac10d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of characters in the corpus is: 1115394\n",
            "The first 200 characters of the corpus are as follows:\n",
            " First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ]
        }
      ],
      "source": [
        "# explore the length of text and the first 200 charactors in the Shakespeare text\n",
        "print('Total number of characters in the corpus is:', len(shakespeare_text))\n",
        "print('The first 200 characters of the corpus are as follows:\\n', shakespeare_text[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4KvcX_lgobS",
        "outputId": "1aae51b2-1d54-4089-9d6b-eb39cb66703b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of unique characters in the corpus is 65\n",
            "A slice of the unique characters set:\n",
            " ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3']\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the corpus\n",
        "vocab = sorted(set(shakespeare_text))\n",
        "print ('The number of unique characters in the corpus is', len(vocab))\n",
        "print('A slice of the unique characters set:\\n', vocab[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPQD-Z8ft0VA"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRHrxiZBcpZO"
      },
      "source": [
        "### Vectorizing the shakespeare_text \n",
        "Before feeding the text to our model, we need to convert the text from a sequence of characters to a sequence of numbers. To do so we will use TextVectorizatoin layer to tokenize shakespeare text form its vocabulary.  After adapting with its  out of it and replace each character with its index in the vocabulary. \n",
        "\n",
        "Note:\n",
        "\n",
        "\n",
        "*   In this exercise, you can use standardize = None, split='character' as TextVectorization arguments since we might need machine to generate capitalcase and some punctualtion corresponding to Shakespeare styles of writting\n",
        "*   After vectorizing text, the unique charactors are 67. Since we need meaningful characters, you must renumber the tokenized text by removing padding (index 0) and unknown words (index 1) since we will not genetate them. For example,the tokenized text after text vectorization is <tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([51, 11,  9, ..., 22, 27, 12])>\n",
        "=> the result of this step must be # tf.Tensor([49  9  7 ... 20 25 10], shape=(1115394,), dtype=int64).\n",
        "*   We don't have to do one-hot encoding at the final step of preparation since we will use loss as SparseCategoricalCrossentropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX0vh6twg1jM",
        "outputId": "0fe84fbe-02f8-4e29-94b7-ad5d85eb74ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', ' ', 'e', 't'] with length 67\n",
            "tf.Tensor([51 11  9 ... 22 27 12], shape=(1115394,), dtype=int64)\n",
            "tf.Tensor([49  9  7 ... 20 25 10], shape=(1115394,), dtype=int64)\n",
            "Vocab size: 65\n"
          ]
        }
      ],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    standardize = None,\n",
        "    split='character',\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"int\",\n",
        ")\n",
        "\n",
        "text_vectorization.adapt([shakespeare_text]) # list that contains string\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "print(vocabulary[:5], \"with length\", len(vocabulary)) # ['', '[UNK]', ' ', 'e', 't'] with length 67\n",
        "text = text_vectorization([shakespeare_text][0]) # string\n",
        "print(text) # <tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([51, 11,  9, ..., 22, 27, 12])>\n",
        "\n",
        "# remove padding (index 0) and unknown words (index 1) since we will not genetate them\n",
        "text = tf.subtract(text,2)\n",
        "print(text) # tf.Tensor([49  9  7 ... 20 25 10], shape=(1115394,), dtype=int64)\n",
        "vocab_size = len(vocabulary) - 2\n",
        "print(\"Vocab size:\", vocab_size) # Vocab size: 65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0Bk22XL6n2XH"
      },
      "outputs": [],
      "source": [
        "# Create a mapping from indices to unique characters for generating text predicted at inference time\n",
        "idx2char = idx2char = dict(enumerate(vocabulary[2:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViGoD7oHsFA3"
      },
      "source": [
        "### Creating an input and output array\n",
        "In this part, we will create an input and output array from the list of tokens from Shackspearean text. Let 's specify the length of corresponding input and target array to be the same size of 100 characters (maxlen = 100) and both are overlapped with 1 charactor. (the target is shifted to the right 1 step ahead)\n",
        "Note: make sure that the input and output array fulfil the following specification:\n",
        "\n",
        "* Input array and an output array, both of size (num_examples, maxlen). You should have num_examples = 11,153.\n",
        "* The input array should contain the 100 tokens of each sequence.\n",
        "* The output array should contain the last 99 characters of input array + 1 (next character token) of each sequence.\n",
        "* To support model to be stateful, we will sample a new sequence every 100 characters so that the next sequence continue where the previous left off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w2Fwak8x78t",
        "outputId": "48d33458-8f01-42c3-d043-36ada009968a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sequences: 11153\n"
          ]
        }
      ],
      "source": [
        "maxlen = 100 # extract sequences of 100 characters\n",
        "shift = 100 # sample a new sequence every 100 characters\n",
        "sentences = [] # keep the extracted input sequences\n",
        "target_sentences = [] # keep the output sequences \n",
        "for i in range(0, len(text) - maxlen-1, shift):\n",
        "  sentences.append(text[i:i+maxlen])\n",
        "  target_sentences.append(text[i+1:i+maxlen+1])\n",
        "print('Number of sequences:', len(sentences))\n",
        "sentences = np.array(sentences)\n",
        "target_sentences = np.array(target_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMHsa62Ls-JX",
        "outputId": "7fc9a0c8-85f1-4b01-c4fc-4827521bab23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11153, 100)\n",
            "(11153, 100)\n"
          ]
        }
      ],
      "source": [
        "# explore shape of input and output arrays\n",
        "print(sentences.shape) # (11154,)\n",
        "print(target_sentences.shape) # (11154,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezOTahHQyll3",
        "outputId": "7548b041-fc8a-4017-e2cd-cac94641e7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[49  9  7  6  2  0 37  9  2  9 57  1  8 24 10 43  1 18  3  7  1  0 17  1\n",
            "  0 23  7  3 19  1  1 12  0  4  8 15  0 18 13  7  2  5  1  7 16  0  5  1\n",
            "  4  7  0 14  1  0  6 23  1  4 28 25 10 10 26 11 11 24 10 35 23  1  4 28\n",
            " 16  0  6 23  1  4 28 25 10 10 49  9  7  6  2  0 37  9  2  9 57  1  8 24\n",
            " 10 50  3 13]\n",
            "[ 9  7  6  2  0 37  9  2  9 57  1  8 24 10 43  1 18  3  7  1  0 17  1  0\n",
            " 23  7  3 19  1  1 12  0  4  8 15  0 18 13  7  2  5  1  7 16  0  5  1  4\n",
            "  7  0 14  1  0  6 23  1  4 28 25 10 10 26 11 11 24 10 35 23  1  4 28 16\n",
            "  0  6 23  1  4 28 25 10 10 49  9  7  6  2  0 37  9  2  9 57  1  8 24 10\n",
            " 50  3 13  0]\n",
            "[ 0  4  7  1  0  4 11 11  0  7  1  6  3 11 27  1 12  0  7  4  2  5  1  7\n",
            "  0  2  3  0 12  9  1  0  2  5  4  8  0  2  3  0 18  4 14  9  6  5 44 10\n",
            " 10 26 11 11 24 10 34  1  6  3 11 27  1 12 25  0  7  1  6  3 11 27  1 12\n",
            " 25 10 10 49  9  7  6  2  0 37  9  2  9 57  1  8 24 10 49  9  7  6  2 16\n",
            "  0 15  3 13]\n",
            "[ 4  7  1  0  4 11 11  0  7  1  6  3 11 27  1 12  0  7  4  2  5  1  7  0\n",
            "  2  3  0 12  9  1  0  2  5  4  8  0  2  3  0 18  4 14  9  6  5 44 10 10\n",
            " 26 11 11 24 10 34  1  6  3 11 27  1 12 25  0  7  1  6  3 11 27  1 12 25\n",
            " 10 10 49  9  7  6  2  0 37  9  2  9 57  1  8 24 10 49  9  7  6  2 16  0\n",
            " 15  3 13  0]\n"
          ]
        }
      ],
      "source": [
        "# explore the first and second training data\n",
        "print(sentences[0])\n",
        "print(target_sentences[0])\n",
        "print(sentences[1])\n",
        "print(target_sentences[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8yC9-zNPEAx",
        "outputId": "7aaf3fb9-e125-474e-a1a4-c8be7a5674f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F i r s t   C i t i z e n : \n",
            " B e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \n",
            " \n",
            " A l l : \n",
            " S p e a k ,   s p e a k . \n",
            " \n",
            " F i r s t   C i t i z e n : \n",
            " Y o u\n",
            "=================\n",
            "i r s t   C i t i z e n : \n",
            " B e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \n",
            " \n",
            " A l l : \n",
            " S p e a k ,   s p e a k . \n",
            " \n",
            " F i r s t   C i t i z e n : \n",
            " Y o u  \n",
            "=================\n",
            "  a r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \n",
            " \n",
            " A l l : \n",
            " R e s o l v e d .   r e s o l v e d . \n",
            " \n",
            " F i r s t   C i t i z e n : \n",
            " F i r s t ,   y o u\n",
            "=================\n",
            "a r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \n",
            " \n",
            " A l l : \n",
            " R e s o l v e d .   r e s o l v e d . \n",
            " \n",
            " F i r s t   C i t i z e n : \n",
            " F i r s t ,   y o u  \n"
          ]
        }
      ],
      "source": [
        "# explore the first and second training data\n",
        "print(\" \".join([idx2char[c] for c in sentences[0]]))\n",
        "print('=================')\n",
        "print(\" \".join([idx2char[c] for c in target_sentences[0]]))\n",
        "print('=================')\n",
        "print(\" \".join([idx2char[c] for c in sentences[1]]))\n",
        "print('=================')\n",
        "print(\" \".join([idx2char[c] for c in target_sentences[1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NkHQjXN1p7O"
      },
      "source": [
        "###Preprocess sequence array for stateful RNN\n",
        "We will build RNN language model to be stateful, so that the internal state of the RNN will be maintained across batches. For this to be effective, we need to make sure that each element of every batch follows on from the corresponding element of the preceding batch\n",
        "\n",
        "The following code processes the input and output sequence arrays so that they are ready to be split into batches for training a stateful RNN, by re-ordering the sequence examples (the rows) according to a specified batch size.<br>\n",
        "you can read how to process the batchs here https://datascience.stackexchange.com/questions/66164/about-batches-in-stateful-rnn \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rGuzMznEzPoL"
      },
      "outputs": [],
      "source": [
        "# Prepare input and output arrays for training the stateful RNN\n",
        "batch_size = 32\n",
        "\n",
        "num_examples = sentences.shape[0] # 11153\n",
        "\n",
        "num_processed_examples = num_examples - (num_examples % batch_size) # 11136\n",
        "\n",
        "sentences = sentences[:num_processed_examples] # shape = (11136, 100)\n",
        "target_sentences = target_sentences[:num_processed_examples] # shape = (11136, 100)\n",
        "\n",
        "steps = int(num_processed_examples / 32)  # steps per epoch\n",
        "#print(steps) # 348\n",
        "inx = np.empty((0,), dtype=np.int32)\n",
        "for i in range(steps):\n",
        "    #print(i,np.arange(0, num_processed_examples, steps)\n",
        "    inx = np.concatenate((inx, i + np.arange(0, num_processed_examples, steps)))\n",
        "\n",
        "#print(inx) # [0,   348,   696, ..., 10439, 10787, 11135]\n",
        "sentences_stateful = sentences[inx] # re-ordering so that the seqeunce are process consecutively \n",
        "# you can read how to process the batchs here https://datascience.stackexchange.com/questions/66164/about-batches-in-stateful-rnn \n",
        "target_sentences_stateful = target_sentences[inx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n3Gt4OQ10Om"
      },
      "source": [
        "### Split the data\n",
        "In this exercise, let' split the data into training set, validation set and test set with the proportion of 70:20:10 percents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zRew8Oi5tm2E"
      },
      "outputs": [],
      "source": [
        "train_size = int(batch_size * ((0.7 * num_processed_examples) // batch_size))\n",
        "val_size = int(batch_size * ((0.9 * num_processed_examples) // batch_size))\n",
        "\n",
        "input_train = sentences_stateful[:train_size]\n",
        "target_train = target_sentences_stateful[:train_size]\n",
        "input_val = sentences_stateful[train_size:val_size]\n",
        "target_val = target_sentences_stateful[train_size:val_size]\n",
        "input_test = sentences_stateful[val_size:]\n",
        "target_test = target_sentences_stateful[val_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhlJgk7juE6C",
        "outputId": "33253650-8c3c-48b8-ce04-06c325adf39d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7776, 100), (2240, 100), (1120, 100))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_train.shape, input_val.shape, input_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa0KBvQ018EX"
      },
      "source": [
        "###Creating the TensorFlow Dataset\n",
        "In this exercise, we will utiize the Dataset from TensorFlow. This is achieved by using tf.data.Dataset to create the dataset object in tensorflow that has a rich set of processing tools to process the data. In this part, you will write the function that create a Dataset using the from_tensor_slices static method, passing in a tuple of the input and output numpy arrays and we will split them into batchs, setting drop_remainder to True. The function should then return the Dataset object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PDUCuoy6t39D"
      },
      "outputs": [],
      "source": [
        "# Complete the following function.\n",
        "# Make sure not to change the function name or arguments.\n",
        "\n",
        "def make_Dataset(input_array, target_array, batch_size):\n",
        "    \"\"\"\n",
        "    This function takes a numpy array batch of input data in the first argument, and\n",
        "    a corresponding array containing the labels in the second argument, and an integer\n",
        "    batch_size in the third argument. It should create and return a Dataset object \n",
        "    using the two numpy arrays and batch size according to the above specification.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_array, target_array))\n",
        "    # Generate batched sequences out of the dataset.\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    \n",
        "    # code for shuffling with in a batch size (optional)\n",
        "    # buffer_size = 10000\n",
        "    # dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oBrT6m6Vt7iM"
      },
      "outputs": [],
      "source": [
        "# Create the training and validation Datasets\n",
        "\n",
        "dataset = make_Dataset(input_train, target_train, batch_size)\n",
        "val_dataset = make_Dataset(input_val, target_val, batch_size)\n",
        "test_dataset = make_Dataset(input_test, target_test, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZgVfCchuaqI",
        "outputId": "822a038b-0044-4cf1-e735-6fc206107354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(TensorSpec(shape=(32, 100), dtype=tf.int64, name=None), TensorSpec(shape=(32, 100), dtype=tf.int64, name=None))\n",
            "(TensorSpec(shape=(32, 100), dtype=tf.int64, name=None), TensorSpec(shape=(32, 100), dtype=tf.int64, name=None))\n",
            "(TensorSpec(shape=(32, 100), dtype=tf.int64, name=None), TensorSpec(shape=(32, 100), dtype=tf.int64, name=None))\n"
          ]
        }
      ],
      "source": [
        "print(dataset.element_spec)\n",
        "print(val_dataset.element_spec)\n",
        "print(test_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxB40E-D0NvP",
        "outputId": "4ee2b692-e83c-4aaa-85e4-adc51c2b77b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 100) (32, 100)\n",
            "(32, 100) (32, 100)\n",
            "(32, 100) (32, 100)\n",
            "(32, 100) (32, 100)\n",
            "(32, 100) (32, 100)\n"
          ]
        }
      ],
      "source": [
        "# take - fetch 5 samples\n",
        "for X_batch, Y_batch in dataset.take(5):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZyXffzE28V0"
      },
      "source": [
        "## Modelling\n",
        "Let's build your language model. The model will receive a sequence of characters and predict the next character in the sequence. At training time, the model can be passed an input sequence, with the output sequence is shifted by one.\n",
        "\n",
        "For example, <br>\n",
        "Input: \"How are y?\" Output: \"ow are yo\" <br>\n",
        "Note the Output is the same length as the input\n",
        "<br>\n",
        "In this part, we will let you complete the function that takes arguments for the vocabulary size (number of tokens) and batch size. Using the Sequential API, your function should build your model according to the following specifications: (In total, the network should have 3 layers.)\n",
        "\n",
        "* The first layer should be an Embedding layer with an  embedding dimension of 256 and set the vocabulary size to vocab_size from the function argument.\n",
        "* The Embedding layer should also mask the zero padding in the input sequences.\n",
        "* The Embedding layer should also set the batch_input_shape to (batch_size, None) (a fixed batch size is required for stateful RNNs).\n",
        "* The next layer should be a (uni-directional) GRU layer with 1024 units, set to be a stateful RNN layer.\n",
        "* The GRU layer should return the full sequence, instead of just the output state at the final time step.\n",
        "* The final layer should be a Dense layer with vocab_size units and no activation function since we use from sparse categorical cross entropy loss with logit=True to reduce softmax computation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vJrq6P-4PKX_"
      },
      "outputs": [],
      "source": [
        "def get_model(vocab_size, batch_size):\n",
        "    \"\"\"\n",
        "    This function takes a vocabulary size and batch size, and builds and returns a \n",
        "    Sequential model according to the above specification.\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "         Embedding(vocab_size, 256, mask_zero=True, batch_input_shape=(batch_size, None)),\n",
        "         GRU(1024, stateful=True, return_sequences=True),\n",
        "         Dense(vocab_size)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J3w4cQkPIiM",
        "outputId": "f3260be1-bf36-4e5b-8d20-786142ae0cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (32, None, 256)           16640     \n",
            "                                                                 \n",
            " gru (GRU)                   (32, None, 1024)          3938304   \n",
            "                                                                 \n",
            " dense (Dense)               (32, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab) # no. of unique characters\n",
        "batch_size = 32\n",
        "\n",
        "model = get_model(vocab_size, batch_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IuYdERSpO3sI"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwDJl53tqdYn",
        "outputId": "bb9a3779-a0be-4df2-9462-8bc6dab39428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "243/243 [==============================] - 1112s 5s/step - loss: 2.1365 - acc: 0.3092 - val_loss: 1.7150 - val_acc: 0.4056\n",
            "Epoch 2/20\n",
            "243/243 [==============================] - 1082s 4s/step - loss: 1.5135 - acc: 0.4720 - val_loss: 1.3621 - val_acc: 0.5243\n",
            "Epoch 3/20\n",
            "243/243 [==============================] - 1014s 4s/step - loss: 1.2369 - acc: 0.5621 - val_loss: 1.1799 - val_acc: 0.5821\n",
            "Epoch 4/20\n",
            "243/243 [==============================] - 1023s 4s/step - loss: 1.0839 - acc: 0.6102 - val_loss: 1.0946 - val_acc: 0.6106\n",
            "Epoch 5/20\n",
            "243/243 [==============================] - 983s 4s/step - loss: 0.9839 - acc: 0.6410 - val_loss: 1.0543 - val_acc: 0.6235\n",
            "Epoch 6/20\n",
            "243/243 [==============================] - 1048s 4s/step - loss: 0.9051 - acc: 0.6660 - val_loss: 1.0386 - val_acc: 0.6306\n",
            "Epoch 7/20\n",
            "243/243 [==============================] - 1115s 5s/step - loss: 0.8348 - acc: 0.6889 - val_loss: 1.0445 - val_acc: 0.6300\n",
            "Epoch 8/20\n",
            "243/243 [==============================] - 1121s 5s/step - loss: 0.7634 - acc: 0.7131 - val_loss: 1.0745 - val_acc: 0.6224\n",
            "Epoch 9/20\n",
            "243/243 [==============================] - 1117s 5s/step - loss: 0.6949 - acc: 0.7378 - val_loss: 1.1191 - val_acc: 0.6191\n",
            "Epoch 10/20\n",
            "243/243 [==============================] - 1096s 5s/step - loss: 0.6323 - acc: 0.7607 - val_loss: 1.1910 - val_acc: 0.6047\n",
            "Epoch 11/20\n",
            "243/243 [==============================] - 1090s 4s/step - loss: 0.5824 - acc: 0.7786 - val_loss: 1.2504 - val_acc: 0.5893\n",
            "Epoch 12/20\n",
            "243/243 [==============================] - 1096s 5s/step - loss: 0.5486 - acc: 0.7897 - val_loss: 1.2694 - val_acc: 0.5981\n",
            "Epoch 13/20\n",
            "243/243 [==============================] - 1092s 4s/step - loss: 0.4944 - acc: 0.8105 - val_loss: 1.3158 - val_acc: 0.6010\n",
            "Epoch 14/20\n",
            "243/243 [==============================] - 1104s 5s/step - loss: 0.4458 - acc: 0.8292 - val_loss: 1.3672 - val_acc: 0.5964\n",
            "Epoch 15/20\n",
            "243/243 [==============================] - 1070s 4s/step - loss: 0.4132 - acc: 0.8409 - val_loss: 1.3985 - val_acc: 0.5981\n",
            "Epoch 16/20\n",
            "243/243 [==============================] - 1001s 4s/step - loss: 0.3882 - acc: 0.8493 - val_loss: 1.4373 - val_acc: 0.5966\n",
            "Epoch 17/20\n",
            "243/243 [==============================] - 1072s 4s/step - loss: 0.3694 - acc: 0.8554 - val_loss: 1.4754 - val_acc: 0.5939\n",
            "Epoch 18/20\n",
            "243/243 [==============================] - 1101s 5s/step - loss: 0.3551 - acc: 0.8601 - val_loss: 1.5173 - val_acc: 0.5874\n",
            "Epoch 19/20\n",
            "243/243 [==============================] - 1138s 5s/step - loss: 0.3446 - acc: 0.8636 - val_loss: 1.5445 - val_acc: 0.5892\n",
            "Epoch 20/20\n",
            "243/243 [==============================] - 1097s 5s/step - loss: 0.3409 - acc: 0.8640 - val_loss: 1.5698 - val_acc: 0.5886\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath='./models/ckpt',\n",
        "                                                           save_weights_only=True,\n",
        "                                                           save_best_only=True)\n",
        "\n",
        "csvlog_callback=tf.keras.callbacks.CSVLogger('history')\n",
        "\n",
        "history = model.fit(dataset, epochs=20,validation_data=val_dataset,callbacks=[checkpoint_callback, csvlog_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sCl-KW7p3LyV",
        "outputId": "9e159669-ac1a-4862-e14f-ad387f562f2a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot the learning curves\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "plt.plot(epochs, history.history['loss'], label = 'loss')\n",
        "plt.plot(epochs, history.history['val_loss'], label = 'val_loss')\n",
        "plt.plot(epochs, history.history['acc'], label = 'acc')\n",
        "plt.plot(epochs, history.history['val_acc'], label = 'val_acc')\n",
        "plt.title('Loss, Accuracy vs Epochs')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2UDKz7q3QBH",
        "outputId": "84dd30aa-f1d2-41bc-a163-5df420e5e357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 26s 754ms/step - loss: 1.5872 - acc: 0.5839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.5871989727020264, 0.5838709473609924]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# measure the accuracy at test set\n",
        "model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q85kPM4vrfLt"
      },
      "source": [
        "### Generate New Text \n",
        "In this part, you will use the model to generate text. However, in order to generate a single text sequence, the model needs to be rebuilt with a batch size of 1. (Because of the way the RNN state is passed from timestep to timestep, the model only accepts a fixed batch size once built.). After building the model, we will feed the single sequence to the model to predict the most likely next letter, add it at the end of the text, then give the extended text to the model to guess the next letter, and so on. These are steps you need to do:\n",
        "1. Restore the latest checkpoint. To keep this prediction step simple, use a batch size of 1. To run the model with a different batch_size which in case is 1, we need to rebuild the model and restore the weights from the checkpoint. \n",
        "2.Prediction the next token based on sampling distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaG3Rr4Qhg-_",
        "outputId": "ae1679e6-92ba-4f25-b2ed-15a23882c433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            16640     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (1, None, 1024)           3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 65)             66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = get_model(vocab_size, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint('./models/'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Y6GoF1rOUP"
      },
      "source": [
        "### The prediction loop\n",
        "The following code block generates the text:\n",
        "\n",
        "It Starts by choosing a start string, initializing the RNN state and setting the number of characters to generate. In order to predict the next token, we will get the prediction distribution of the next character using the start string and the RNN state. Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model.\n",
        "\n",
        "The RNN state returned by the model is fed back into the model so that it now has more context, instead than only one character. After predicting the next character, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wptNCF1ohofx"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, num_generate, temperature, start_string):\n",
        "  input_eval = text_vectorization(start_string) # string to numbers (vectorizing)\n",
        "  input_eval -= 2 # to remove padding and unknown tokens\n",
        "  input_eval = tf.expand_dims(input_eval, 0) # dimension expansion at axis0 () \n",
        "  text_generated = [] # Empty string to store our results\n",
        "  model.reset_states() # Clears the hidden states in the RNN\n",
        "\n",
        "  for i in range(num_generate): #Run a loop for number of characters to generate\n",
        "    predictions = model(input_eval) # prediction for single character\n",
        "    predictions = tf.squeeze(predictions, 0) # remove the batch dimension\n",
        "    \n",
        "    # using a categorical distribution to predict the character returned by the model\n",
        "    # higher temperature increases the probability of selecting a less likely character\n",
        "    # lower --> more predictable\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    # The predicted character as the next input to the model\n",
        "    # along with the previous hidden state\n",
        "    # So the model makes the next prediction based on the previous character\n",
        "    input_eval = tf.expand_dims([predicted_id], 0) \n",
        "    # Also devectorize the number and add to the generated text\n",
        "    text_generated.append(idx2char[predicted_id]) \n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gEG7GUwhpKh",
        "outputId": "15dd1534-0aea-4a03-c746-0ec23b074dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizens,\n",
            "And for Lord Clifford and Signior Prince,\n",
            "That France know Upon \n",
            "The Senate $ Now I Do th ! :\n",
            "I  Jon so, zenona : ?\n",
            "\n",
            "CLARENCE:\n",
            "Then 3 $ar for \n",
            "A amelled, cousin for Securate William.\n",
            "\n",
            "CLARENCE:\n",
            "The join 3 be Zount's ence, very William venture.\n",
            "\n",
            "KING DENRY quencle, 3 ay, I \n",
            "marry may Zouncillain ERward \n",
            "And Stand York , : know A age llow Sand France,\n",
            "That xarting s England Warwick have Warwick xather country's country,\n",
            "It  just 's -wounds in the Unless Richard I God Bickly Send Henry.\n",
            "\n",
            "BRAKENB\n"
          ]
        }
      ],
      "source": [
        "generated_text = generate_text(\n",
        "                    model, \n",
        "                    num_generate=500, \n",
        "                    temperature=0.2, \n",
        "                    start_string=u\"First Citizen\")\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zznhio0iqkga"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
